### bgpls-broker

This project is a work in progress that exposes an API to the user what the network looks like using BGP Link State (BGP-LS). For more details, I recommend you take a look at these RFCs:

- https://tools.ietf.org/html/rfc8571
- https://tools.ietf.org/html/rfc7752

Brief summary:

ExaBGP is used as a control plane BGPLS ingestor, which we can attach a python script to the specific neighbor and ensure all updates received by this neighbor are processed via stdin. This data is then published to a RabbitMQ exchange (for the purpose of introducing multiple consumers if required).

Consumers (exabgpapi_workers) will then process these BGP messages and perform specific tasks such as creating/updating/removing entries in the database. BGPLS links and prefixes can be tied to a BGPLS node based on the ASN + Router ID (and IGP domain if we are talking about something like a unified MPLS/disjointed segment routing scenario)

The bgplsapi will then expose a few basic endpoints (using Flask) to query the existing database or build the specific ASN and return all the nodes with their respective links + prefixes. Below you can find an example of the flow/architecture for the bgpls-broker project:

![bgplsapi Architecture](/img/bgplsapi-architecture.jpg)

Sample configurations for exabgp and vendor configurations can be found at: [samples](../blob/master/samples/)

The application tries to maintain the state of the network based on UPDATEs received from the ExaBGP api. BGP-LS Nodes have a generated "node_id" which is globally unique as per ![BGP-LS extensions for Segment Routing](https://tools.ietf.org/html/draft-ietf-idr-bgpls-segment-routing-epe-19). The node_id is generated by using the ASN:Router-ID. These tuple values should be globally unique (otherwise your network is designed wrong). BGPLS-Links and BGPLS-Prefixes will have a relationship to a BGPLS-Node and therefore the API is able to pull all related BGP-LS Updates for a given ASN/Node.

Upon receiving an update to an existing entry in the database, it will update the entry. If a withdraw has been received then the workers will simply delete this based on a fairly strict search (eg. BPGLS-Node uses on the node_id but BGPLS-Link will check node_id, l3_routing_topology, interface-address and more...)

If a neighborship goes down between ExaBGP and the network, this is relayed to the API and will perform a cleanup for any related entries in the database (BGPLS-Node/Link/Prefixes) and will flush out the database. I have yet to still improve this feature/general database operations and cleanups since the database may not always be in sync with the network when the containers are restarted.

Currently, the API only exposes a few endpoints for the user. Here are the useful ones to gather some data if you are trying out this project and have successfully peered with the ExaBGP container from your network.

- /api/get_topology/<asn> - Returns the topology (more like a TED if TE functions are enabled) for given ASN
- /api/mongodb/get_collections - Returns the collections (eg. neighbor_state, bgpls_node, bgpls_links, bgpls_prefixes_v4 and bgpls_prefixes_v6)
- /api/mongodb/neighbor_state - Returns all entries in the neighbor_state collection
- /api/mongodb/bgpls_nodes - Returns all entries in the bgpls_nodes collection
- /api/mongodb/bgpls_links - Returns all entries in the bgpls_links collection
- /api/mongodb/bgpls_prefixes_v4 - Returns all entries in the bgpls_prefixes_v4 collection
- /api/mongodb/delete_collection/<collection> - Removes all entries in the collection specified.

You can find examples of what data is exposed from these databases in the samples folder (linked at the start of the readme). Please not that these samples may not be the most recent representation of data in the future if I forget to update documentation.

This project is not production ready and I would advise to run it in a lab if you want to play around with it.

## Low Level Design

How does this application work on a low level? What are all the moving parts?

Currently, everything is powered by 3 main parts:

1. ExaBGP
2. RabbitMQ
3. MongoDB

### ExaBGP

ExaBGP is used to peer with the network using the BGP Link State AFI/SAFI. A python script is then attached to the neighbor process which will essentially read ExaBGPs existing JSON encoder (which are the BGP updates read from stdin) and these messages are then published to RabbitMQ. The concept is that each IGP area in a disjoint network will peer with a local router to grab the LSDB information and process any local updates (scalability concept).

The exabgpapi_worker will consume messages from the RabbitMQ exchange and perform tasks such as creating/updating/deleting entries in the Mongo database. Another concept here is to have multiple exabgpapi_workers if 1 is too little to process all the BGP updates from the rabbitmq queue. Each BGP UPDATE is processed and depending on the update type (eg. a bgpls-node vs bgpls-link update or withdraw), will interact with the database and try to maintain the existing network state (based on the received BGP updates).

### RabbitMQ

RabbitMQ is a message broker and is currently just used as a concept to introduce more apps to consume from the bgplsapi exchange (but replicated potentially to another exchange/queue?) to allow the user to introduce their own applications or workers so they are not limited to just MongoDB for example. The user can process the BGP updates in a MySQL database or just use it on demand.

This part of the application also helps with the multiple workers concept, where if 1 worker is not enough to process the updates and perform actions against the Mongo database, we can just introduce another RabbitMQ consumer and have fixed a scalability issue if the worker was struggling due to memory constraints. However during my testing, I haven't ran into any issues running a single worker but I am not processing hundreds of updates a second. (sounds more like an unstable network...!!!)

### MongoDB

MongoDB is used purely for the sake of dumping the majority of the BGP JSON messages processed directly from ExaBGP without having to manage relationships or formatting the data... Some manual processing is done to figure out eg. which BGPLS node a specific BGPLS link or prefix belongs to, however it is quite minimal and just filters through the JSON a few levels.


I still need to provide good examples/demos on my concept of the disjointed network, and showing proof that you can effectively build something like an end-to-end LSP based on the LSDB + TED. My idea is that technically the database being maintained just gives the user a basic JSON format of the existing LSDB and MPLS TED. Local routers are processing changes and the LSDB is constantly changing, these changes are then reflected on the BGP-LS router in that specific area and then sent to ExaBGP, as long as we maintain the database then we should have a fairly up to date topology of the existing network (including disjoint networks).